# RL Homework

### How to submit
Задачи отправляются боту в Telegram: `@RL_hw_bot`. В качестве решения задачи принимается zip-архив с кодом. Важно: содержимое папки с задание должно быть в корне, иначе бот не найдет ваше решение. Например, для первого задания, находящегося в папке `hw01_mountain_car`, все файлы из этой папки должны находиться в корне архива.

### Task
В этом задании нужно реализовать агента, который способен быстро исследовать неизвестную среду. Особенность задачи в том, что агент обучается на сервере вслепую.
Что нужно знать о среде:
1) Континуальный state space.
2) Дискретный action space.
3) Количество шагов в эпизоде ограничено сверху.
4) Победа в игре - достижение определенного состояния. После достижения победного состояния эпизод завершается досрочно, а агент получает награду в размере 10 очков.
5) За действия, которые не привели к победе, агент получает 0 очков.


### Оценка:
Оценка выставляется от 1 до 10 и линейно зависит от количества посещений агентом победных состояний во время 100 эпизодов обучения. Максимальная оценка выставляется за 70+ посещений победного состояния, минимальная оценка выставляется за 0+ посещений победного состояния.

### Рекомендации:
1) В качестве baseline лучше всего использовать DQN и Random Network Distillation. В RND случайная сеть должна быть большой, а обучаемая сеть - маленькой. Также не стоит использовать большой learning rate.
2) Можно добавить epsilon-greedy, но очивидно, что значение эпсилон должно быть маленьким.
3) Во всех exploration-методах на каждом переходе среды стоит обучаться не более одного раза. Это позволит методу лучше выделять те переходы, которые агент совершает редко.
